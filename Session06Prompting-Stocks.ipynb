{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmeLG3RXhXpcjMVVKeHKhS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Murthy-Kolluru/modelthinking/blob/main/Session06Prompting-Stocks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Mount google drive\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVUxEl7rtHyY",
        "outputId": "5a193ca6-8eef-42f0-c0d9-2c21c427e97a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create folder\n",
        "import os\n",
        "\n",
        "# Define the directory path\n",
        "directory_path = '/content/drive/My Drive/stocks'\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "if not os.path.exists(directory_path):\n",
        "    os.makedirs(directory_path)\n"
      ],
      "metadata": {
        "id": "BLrNjXXltsa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWxKtd_9sgmZ",
        "outputId": "e0f07fe3-31dd-4a1c-be03-684b3402cdd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n"
          ]
        }
      ],
      "source": [
        "#Download data\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# List of stock tickers\n",
        "stock_tickers = ['AAPL', 'MSFT', 'F', 'CSCO', 'PFE', 'WMT', 'JPM', 'ACN', 'JNJ', 'PG']\n",
        "\n",
        "# Fetch historical data for each stock\n",
        "stock_data = {}\n",
        "for ticker in stock_tickers:\n",
        "    stock_data[ticker] = yf.download(ticker, start=\"2004-01-01\", end=\"2024-01-01\")\n",
        "\n",
        "# Extract daily closing values\n",
        "closing_values = {}\n",
        "for ticker, data in stock_data.items():\n",
        "    closing_values[ticker] = data['Close']\n",
        "\n",
        "# Write closing values to CSV and store in Google Drive\n",
        "for ticker, closes in closing_values.items():\n",
        "    file_name = f\"{ticker}_closing_values.csv\"\n",
        "    closes.to_csv(f\"/content/drive/My Drive/stocks/{file_name}\")\n",
        "\n",
        "# Display first five and last five values in table format\n",
        "#print(\"First five and last five values of all stocks:\")\n",
        "#for ticker, closes in closing_values.items():\n",
        " #   print(f\"\\n{ticker}\")\n",
        "  #  print(pd.concat([closes.head(), closes.tail()]))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create annual data files for each stock\n",
        "\n",
        "def split_into_annual_files(stock_data, directory_path):\n",
        "    # Iterate over each stock's data\n",
        "    for ticker, data in stock_data.items():\n",
        "        print(f\"Processing data for {ticker}...\")\n",
        "\n",
        "        # Create folder for the stock if it doesn't exist\n",
        "        stock_folder = os.path.join(directory_path, ticker)\n",
        "        if not os.path.exists(stock_folder):\n",
        "            os.makedirs(stock_folder)\n",
        "\n",
        "        # Split data into annual stock values and save as separate files\n",
        "        for year in range(data.index.year.min(), data.index.year.max() + 1):\n",
        "            annual_data = data[str(year)]\n",
        "            file_name = f\"{year}_closing_values.csv\"\n",
        "            file_path = os.path.join(stock_folder, file_name)\n",
        "            annual_data.to_csv(file_path)\n",
        "\n",
        "# Example usage\n",
        "split_into_annual_files(stock_data, '/content/drive/My Drive/stocks')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t67KM7Lry0qO",
        "outputId": "a3e61712-73ff-488e-8a8d-5a4fc3e1fc4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing data for AAPL...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-b7da15fdf3c1>:15: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
            "  annual_data = data[str(year)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing data for MSFT...\n",
            "Processing data for F...\n",
            "Processing data for CSCO...\n",
            "Processing data for PFE...\n",
            "Processing data for WMT...\n",
            "Processing data for JPM...\n",
            "Processing data for ACN...\n",
            "Processing data for JNJ...\n",
            "Processing data for PG...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Delete the original 20 year files\n",
        "\n",
        "def delete_original_files(directory_path):\n",
        "    # Iterate over files in the directory\n",
        "    for root, dirs, files in os.walk(directory_path):\n",
        "        for file in files:\n",
        "            # Check if the file is a CSV file containing the original 20-year data\n",
        "            if file.endswith(\"_closing_values.csv\") and not any(f\"{year}_\" in file for year in range(2004, 2024)):\n",
        "                file_path = os.path.join(root, file)\n",
        "                os.remove(file_path)\n",
        "                print(f\"Deleted {file_path}\")\n",
        "\n",
        "# Example usage\n",
        "delete_original_files('/content/drive/My Drive/stocks')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEZlPpz0zccW",
        "outputId": "dcdecd0e-7fab-432a-a549-2864f69bbcfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted /content/drive/My Drive/stocks/AAPL_closing_values.csv\n",
            "Deleted /content/drive/My Drive/stocks/MSFT_closing_values.csv\n",
            "Deleted /content/drive/My Drive/stocks/F_closing_values.csv\n",
            "Deleted /content/drive/My Drive/stocks/CSCO_closing_values.csv\n",
            "Deleted /content/drive/My Drive/stocks/PFE_closing_values.csv\n",
            "Deleted /content/drive/My Drive/stocks/WMT_closing_values.csv\n",
            "Deleted /content/drive/My Drive/stocks/JPM_closing_values.csv\n",
            "Deleted /content/drive/My Drive/stocks/ACN_closing_values.csv\n",
            "Deleted /content/drive/My Drive/stocks/JNJ_closing_values.csv\n",
            "Deleted /content/drive/My Drive/stocks/PG_closing_values.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Compute and store annual returns and risks\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "def compute_annual_return_and_risk(stock_data, directory_path):\n",
        "    # Create an empty DataFrame to store annual returns and risks for each ticker and year\n",
        "    annual_return_risk_df = pd.DataFrame()\n",
        "\n",
        "    # Create an empty list to store years\n",
        "    years = []\n",
        "\n",
        "    # Iterate through every ticker and every year\n",
        "    for ticker, data in stock_data.items():\n",
        "        print(f\"Processing data for {ticker}...\")\n",
        "\n",
        "        # Create empty lists to store annual returns and risks for each year\n",
        "        annual_returns = []\n",
        "        annual_risks = []\n",
        "\n",
        "        for year in range(data.index.year.min(), data.index.year.max() + 1):\n",
        "            annual_data = data.loc[str(year)]\n",
        "\n",
        "            # Compute daily returns starting from the second data point in each year\n",
        "            daily_returns = annual_data['Close'].pct_change().dropna()\n",
        "\n",
        "            # Calculate annual return for the year\n",
        "            annual_return = daily_returns.mean()\n",
        "\n",
        "            # Calculate annual risk (standard deviation) for the year\n",
        "            annual_risk = daily_returns.std()\n",
        "\n",
        "            # Append year to the list if it's not already in the list\n",
        "            if year not in years:\n",
        "                years.append(year)\n",
        "\n",
        "            # Append annual return and risk to the respective lists\n",
        "            annual_returns.append(annual_return)\n",
        "            annual_risks.append(annual_risk)\n",
        "\n",
        "        # Pad the lists with NaN values for the missing years\n",
        "        annual_returns.extend([np.nan] * (len(annual_return_risk_df) - len(annual_returns)))\n",
        "        annual_risks.extend([np.nan] * (len(annual_return_risk_df) - len(annual_risks)))\n",
        "\n",
        "        # Add the 'Year' column to the DataFrame\n",
        "        annual_return_risk_df['Year'] = years\n",
        "\n",
        "        # Add annual returns and risks to the DataFrame\n",
        "        annual_return_risk_df[f\"{ticker}-returns\"] = annual_returns\n",
        "        annual_return_risk_df[f\"{ticker}-risks\"] = annual_risks\n",
        "\n",
        "    # Store the DataFrame in a CSV file\n",
        "    annual_return_risk_df.to_csv(os.path.join(directory_path, \"annual-return-risk.csv\"))\n",
        "\n",
        "# Example usage\n",
        "compute_annual_return_and_risk(stock_data, '/content/drive/My Drive/stocks')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDa04TRt4GXh",
        "outputId": "c483739a-9685-4bea-9bc1-eb508bd7c638"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing data for AAPL...\n",
            "Processing data for MSFT...\n",
            "Processing data for F...\n",
            "Processing data for CSCO...\n",
            "Processing data for PFE...\n",
            "Processing data for WMT...\n",
            "Processing data for JPM...\n",
            "Processing data for ACN...\n",
            "Processing data for JNJ...\n",
            "Processing data for PG...\n"
          ]
        }
      ]
    }
  ]
}